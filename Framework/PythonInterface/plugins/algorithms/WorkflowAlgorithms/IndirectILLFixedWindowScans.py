#pylint: disable=no-init
from __future__ import (absolute_import, division, print_function)


from mantid.simpleapi import *  # noqa
from mantid.api import DataProcessorAlgorithm, AlgorithmFactory, \
    WorkspaceGroupProperty, FileProperty, MultipleFileProperty, FileAction
from mantid.kernel import Direction, logger, StringListValidator
import numpy as np
import re


# This function already exists in IndirectILLReduction
def monitor_range(workspace):
    """
    Get sensible x-range where monitor count is not zero
    Used to mask out the first and last few channels
    @param workspace :: name of workspace
    @return   :: tuple of xmin and xmax
    """
    x_values = mtd[workspace].readX(0)
    y_values = mtd[workspace].readY(0)
    # mid x value in order to search for left and right monitor range delimiter
    size = len(x_values)
    # Maximum search in left and right half of the workspace
    mid = int(size / 2)
    # Maximum position left (differs from IndirectILLReduction)
    imin = np.nanargmax(np.array(y_values[0:mid]))
    # Maximum position right
    imax = np.nanargmax(np.array(y_values[mid:size])) + 1 + mid
    return x_values[imin], x_values[imax]


class IndirectILLFixedWindowScans(DataProcessorAlgorithm):

    _run_file = None
    _background_file = None
    _calibration_file = None

    _debug_mode = None

    _out_ws = None
    _analyser = None
    _reflection = None
    _sortX = False

    selected_runs = None

    _observable_name = None
    _observable = None

    def category(self):
        return 'Workflow\\MIDAS;Inelastic\\Reduction'

    def summary(self):
        return 'Reduction for IN16B elastic and inelastic fixed-window scans.'

    def name(self):
        return "IndirectILLFixedWindowScans"

    def PyInit(self):
        self.declareProperty(MultipleFileProperty(name='Run',
                                                  extensions=['nxs']),
                             doc='List of input file (s)')

        self.declareProperty(name='Observable',
                             defaultValue='sample.temperature',
                             doc='Scanning observable, a Sample Log entry\n')

        self.declareProperty(name='SortXAxis',
                             defaultValue=False,
                             doc='Whether or not to sort the x-axis\n')

        # Not yet implemented
        self.declareProperty(name='PerformCurveFitting',
                             defaultValue='False',
                             doc='Fit post-processed curve; \n'
                                 'only for elastic scan data.')

        self.declareProperty(FileProperty('MapFile', '',
                                          action=FileAction.OptionalLoad,
                                          extensions=['xml']),
                             doc='Filename of the detector grouping map file. \n'
                                 'If left blank the default will be used.')

        self.declareProperty(name='Analyser',
                             defaultValue='silicon',
                             validator=StringListValidator(['silicon']),
                             doc='Analyser crystal.')

        self.declareProperty(name='Reflection',
                             defaultValue='111',
                             validator=StringListValidator(['111', '311']),
                             doc='Analyser reflection.')

        self.declareProperty(name='DebugMode',
                             defaultValue=False,
                             doc='Whether to output the workspaces in intermediate steps. \n'
                                 'Generated by IndirectILLReduction.')

        self.declareProperty(MultipleFileProperty('BackgroundRun',
                                                  action=FileAction.OptionalLoad,
                                                  extensions=['nxs']),
                             doc='File path of background run(s).')

        self.declareProperty(MultipleFileProperty('CalibrationRun',
                                                  action=FileAction.OptionalLoad,
                                                  extensions=['nxs']),
                             doc='File path of calibration run(s).')

        self.declareProperty(WorkspaceGroupProperty('OutputWorkspace', 'output',
                                                    direction=Direction.Output),
                             doc='Output workspace group')

    def validateInputs(self):

        issues = dict()

        return issues

    def setUp(self):

        self._run_file = self.getPropertyValue('Run')
        self._map_file = self.getPropertyValue('MapFile')
        self._analyser = self.getPropertyValue('Analyser')
        self._reflection = self.getPropertyValue('Reflection')
        self._debug_mode = self.getProperty('DebugMode').value
        self._background_file = self.getPropertyValue('BackgroundRun')
        self._calibration_file = self.getPropertyValue('CalibrationRun')
        self._out_ws = self.getPropertyValue('OutputWorkspace')
        self._observable_name = self.getPropertyValue('Observable')
        self._sortX = self.getProperty('SortXAxis').value

        # load background run if needed
        if self._background_file:
            # Call ILLReduction for background file and do something here
            self.log().information('Loaded background run: {0}'.format(self._background_file))

        # load vanadium run if needed
        if self._calibration_file:
            # Call ILLReduction for calibration file and do something here
            self.log().information('Loaded calibration run: {0}'.format(self._calibration_file))

    def PyExec(self):

        self.setUp()

        # Check whether observable exists in Nexus file
        _criteria = '$/entry0/' + self._observable_name.replace('.', '/') + '$ or True'
        self.log().debug('Filtering with nexus criteria: {0}'.format(_criteria))
        self._run_file = SelectNexusFilesByMetadata(self._run_file, _criteria)

        if self._run_file == '':
            self.log().error('Observable not found in Sample Logs')
            raise RuntimeError('Observable not found in Sample Logs')

        self.log().information('Call IndirectILLReduction for .nxs file(s) : {0}'.format(self._run_file))
        IndirectILLReduction(Run=self._run_file, MapFile=self._map_file, Analyser=self._analyser,
                             Reflection=self._reflection, ReductionType='FWS', DebugMode=self._debug_mode,
                             UnmirrorOption=1, OutputWorkspace=self._out_ws)

        self.selected_runs = []

        # Traverse over items in workspace group and reduce individually
        for i in range(mtd[self._out_ws].size()):
            # Get name of the i-th workspace
            input_ws = format(mtd[self._out_ws].getItem(i).getName())

            self.log().debug('Reducing run #'.format(input_ws))

            self._reduce_run(input_ws)

            self.selected_runs.append(input_ws)

        self._set_workspace_properties()

    def _reduce_run(self, input_ws):
        """
        Performs the reduction for a given single run according to Doppler settings
        @param input_ws :: string of input workspace to reduce, will be overridden
        """
        self.log().information('Reducing run #' + input_ws)
        x_values = mtd[input_ws].readX(0)

        energy = mtd[input_ws].getRun().getLogData('Doppler.maximum_delta_energy').value

        if energy == 0.:
            # Elastic, take full 'energy range'
            logger.information('EFWS scan from {0} to {1}'.format(x_values[0], x_values[-1]))
            Integration(InputWorkspace=input_ws, OutputWorkspace=input_ws,
                        RangeLower=x_values[0], RangeUpper=x_values[-1])
        else:
            # Inelastic
            # Get the two maximum peak positions of the inelastic fixed-window scan
            x_min, x_max = monitor_range(input_ws)
            # Enlarge integration interval on left and right side, take into account the overall blocksize (in general
            # variable for each experiment)
            int_interval = int(mtd[input_ws].blocksize() / 50)
            delta_x = x_values[1] - x_values[0]
            x_min += int_interval * delta_x
            x_max -= int_interval * delta_x
            self.log().information('IFWS scan ranges [{0} {1}] and [{2} {3}]'.format
                                   (x_values[0], x_min, x_max, x_values[len(x_values) - 1]))
            Integration(InputWorkspace=input_ws, OutputWorkspace='__left',
                        RangeLower=x_values[0], RangeUpper=x_min)
            Integration(InputWorkspace=input_ws, OutputWorkspace='__right',
                        RangeLower=x_max, RangeUpper=x_values[len(x_values) - 1])
            Plus(LHSWorkspace='__left', RHSWorkspace='__right', OutputWorkspace=input_ws)

    def _get_observable(self, input_ws):
        """
        Set list self._observable
        Args:
            input_ws: GroupWorkspace, all reduced workspaces of one energy
        """
        self._observable = []
        for index in range(mtd[input_ws].getNumberOfEntries()):
            entity = mtd[input_ws].getItem(index).getRun().getLogData(self._observable_name).value
            if self._observable_name != 'start_time':
                entity = float(entity)
            else:
                # start_time is a string like 2016-09-12T09:09:15 (date using hyphen T time using colon)
                entity = str(entity)
                # Get all numbers
                entity = re.findall(r'\d+', entity)
                hours = int(entity[3])
                minutes = int(entity[4])
                seconds = int(entity[5])
                entity = seconds + 60 * minutes + 3600 * hours
                # Improvement possible: account for different days!

            self.log().debug('{0}: {1}'.format(self._observable_name, entity))
            self._observable.append(entity)

    def _create_matrix(self, group, output_ws):
        """
        Args:
            group : GroupWorkspace, will be transformed to one MatrixWorkspace, Workspace2D, not a histogram
            output_ws : name of the output workspace

        """
        self._get_observable(group)

        number_hists = mtd[group].getItem(0).getNumberHistograms()
        number_workspaces = mtd[group].getNumberOfEntries()
        length = number_workspaces * number_hists

        self.log().notice('Final post-processing workspace has {0} channel(s) and {1} spectra'.format(number_workspaces,
                                                                                                      number_hists))

        # Initialisation of the new workspace with values of the first workspace
        y_values = np.zeros([1, length])
        e_values = np.zeros([1, length])
        x_values = np.zeros([1, length])
        # Variable that will store one row of the final matrix
        y_row = np.zeros(number_workspaces)
        e_row = np.zeros(number_workspaces)

        CreateWorkspace(DataX=x_values, DataY=y_values, DataE=e_values, NSpec=number_hists,
                        WorkspaceTitle=output_ws, Distribution=True, ParentWorkspace=mtd[group].getItem(0),
                        OutputWorkspace=output_ws)

        # Get and set workspace entries
        for hist in range(number_hists):
            mtd[output_ws].setX(hist, np.array(self._observable))
            for index in range(number_workspaces):
                workspace = mtd[group].getItem(index)
                y_row[index] = workspace.readY(hist)
                e_row[index] = workspace.readE(hist)
            mtd[output_ws].setY(hist, y_row)
            mtd[output_ws].setE(hist, e_row)

        if self._sortX:
            SortXAxis(InputWorkspace=output_ws, OutputWorkspace=output_ws)

        run_numbers = []
        for index in range(number_workspaces):
            run_numbers.append(mtd[group].getItem(index).getRun().getLogData('run_number').value)

        # Save run number for files of selected energy
        AddSampleLog(Workspace=output_ws, LogName='ReducedRuns', LogText=str(run_numbers))

        # Label x-values
        axis = mtd[output_ws].getAxis(0)
        if self._observable_name == 'sample.temperature':
            axis.setUnit("Label").setLabel('Temperature', 'K')
        elif self._observable_name == 'sample.pressure':
            axis.setUnit("Label").setLabel('Pressure', 'P')
        elif self._observable_name == 'start_time':
            axis.setUnit("Label").setLabel('Time', 'seconds')
        else:
            axis.setUnit("Label").setLabel(self._observable_name, 'Unknown')

    def _get_energies(self):
        '''
        Returns: energies   a list of unique energies
                 indices    indices of the energy values

        '''
        energies = []
        number_of_workspaces = mtd[self._out_ws].getNumberOfEntries()

        # Count appearances of energy, this will be the number of GroupWorkspaces needed
        for i in range(number_of_workspaces):
            the_workspace = mtd[self._out_ws].getItem(i).getRun()
            if the_workspace.hasProperty('Doppler.maximum_delta_energy'):
                energy = round(the_workspace.getLogData('Doppler.maximum_delta_energy').value, 2)
            else:
                energy = float('nan')
            energies.append(energy)

        # return_counts would be nice to use here but requires numpy version 1.9.0
        energy_values, indices = np.unique(energies, return_inverse=True)
        self.log().information('FWS energies: {0}'.format(energy_values))
        self.log().debug('Corresponding workspaces (index): {0}'.format(indices))

        return [energy_values, indices]

    def _get_list_of_workspace_names(self):
        '''

        Returns: a list of all workspaces after calling IndirectILLReduction

        '''
        _selected_runs = []
        number_of_workspaces = mtd[self._out_ws].getNumberOfEntries()
        for i in range(number_of_workspaces):
            _selected_runs.append(re.findall(r'\d+', self.selected_runs[i]))
        self.log().debug('List of runs: {0}'.format(_selected_runs))

        return _selected_runs

    def _set_workspace_properties(self):
        """
        Sets the properties of each GroupWorkspace for each elastic and inelastic energy

        """

        number_of_workspaces = mtd[self._out_ws].getNumberOfEntries()

        energy_values, indices = self._get_energies()

        number_groups = len(energy_values)
        self.log().debug('Number of GroupWorkspaces {0}'.format(number_groups))

        _selected_runs = self._get_list_of_workspace_names()

        UnGroupWorkspace(self._out_ws)

        # List of final output workspaces
        matrices = []

        for mygroup in range(number_groups):
            self.log().debug('Group of energy {0} micro eV'.format(energy_values[mygroup]))

            # Create a new list for each new group of workspaces
            group = []
            # Create GroupWorkspace name of the energy group
            group_name = 'group' + str(energy_values[mygroup])

            # Add the workspaces to the group, which belong to the same energy
            for ith_workspace in range(number_of_workspaces):
                if mygroup == indices[ith_workspace]:
                    # Pick workspace with same energy value
                    self.log().debug('Join workspace {0}'.format(_selected_runs[ith_workspace][0] + '_' + self._out_ws))
                    group.append(_selected_runs[ith_workspace][0] + '_' + self._out_ws)

            # Create a GroupWorkspace
            self.log().debug('GroupWorkspaces {0} for grouping {1}'.format(group_name, group))
            GroupWorkspaces(InputWorkspaces=group, OutputWorkspace=group_name)

            # Create an additional workspace containing all workspaces of the group (transversed)
            matrix = self._out_ws + '_' + str(energy_values[mygroup])
            self._create_matrix(group_name, matrix)
            matrices.append(matrix)

            DeleteWorkspace(group_name)

        self.log().notice('Set OutputWorkspace property for grouped workspaces {0}'.format(matrices))
        GroupWorkspaces(InputWorkspaces=matrices, OutputWorkspace=self._out_ws)
        self.setProperty('OutputWorkspace', self._out_ws)

AlgorithmFactory.subscribe(IndirectILLFixedWindowScans)
